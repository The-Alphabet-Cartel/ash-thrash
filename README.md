# üß™ Ash-Thrash: Comprehensive Crisis Detection Testing Suite

> *Thrashing the system to find failures before they find you*

## What is Ash-Thrash?

Ash-Thrash is a comprehensive testing framework designed specifically for **The Alphabet Cartel's** [Ash Discord Bot](https://github.com/The-Alphabet-Cartel/ash) NLP crisis detection system. It systematically tests crisis detection accuracy and speed using **350 carefully crafted test phrases** across **7 priority categories**.

**Repository:** https://github.com/The-Alphabet-Cartel/ash-thrash  
**Main Ash Bot:** https://github.com/The-Alphabet-Cartel/ash  
**NLP Server:** https://github.com/The-Alphabet-Cartel/ash-nlp  
**Dashboard:** https://github.com/The-Alphabet-Cartel/ash-dash  
**Discord:** https://discord.gg/alphabetcartel

## üéØ Why Ash-Thrash?

Crisis detection systems save lives, but they need to be **thoroughly tested** to ensure they work when it matters most. Ash-Thrash provides:

- **Comprehensive Testing** - 350 phrases covering every crisis scenario
- **Safety-First Validation** - 100% catch rate for high-priority crises  
- **False Positive Prevention** - 95% accuracy for non-crisis messages
- **Performance Monitoring** - Speed and accuracy metrics over time
- **Dashboard Integration** - Real-time results in ash-dash
- **Automated Scheduling** - Continuous testing without manual intervention

---

## üéØ Testing Goals & Targets

Ash-Thrash tests **350 unique phrases** designed to stress-test every aspect of crisis detection:

| Priority Level | Test Phrases | Target Catch Rate | Critical? | Safety Impact |
|----------------|--------------|-------------------|-----------|---------------|
| **üö® Definite High** | 50 phrases | **100%** | ‚úÖ CRITICAL | Lives depend on this |
| **‚ö†Ô∏è Definite Medium** | 50 phrases | **65%** | - | Important for support |
| **üîç Definite Low** | 50 phrases | **65%** | - | General wellness |
| **‚úÖ Definite None** | 50 phrases | **95%** | ‚úÖ CRITICAL | Prevent alert fatigue |
| **üìà Maybe High/Medium** | 50 phrases | **90%** | - | Allow escalation only |
| **üìä Maybe Medium/Low** | 50 phrases | **80%** | - | Allow escalation only |
| **üìâ Maybe Low/None** | 50 phrases | **90%** | ‚úÖ CRITICAL | Prevent false positives |

### üîç What Makes This Special?

- **"Maybe" Categories** test edge cases where escalation is OK but de-escalation is dangerous
- **Definite Categories** require exact priority matching
- **Safety-First Design** prioritizes catching real crises over avoiding false positives
- **Real-World Phrases** based on actual community language patterns

---

## üöÄ Quick Start

### Prerequisites
- **Docker & Docker Compose** (for containerized deployment)
- **Python 3.11+** (for local development)
- **Access to Ash NLP Server** (default: `10.20.30.16:8881`)
- **Windows 11 compatible** (developed for your environment)

### One-Command Setup

```bash
# Clone and setup everything
git clone https://github.com/The-Alphabet-Cartel/ash-thrash.git
cd ash-thrash
bash setup.sh
```

### Manual Setup

```bash
# Clone the repository
git clone https://github.com/The-Alphabet-Cartel/ash-thrash.git
cd ash-thrash

# Copy and configure environment
cp .env.template .env
# Edit .env with your NLP server details (default works for most setups)

# Start with Docker (recommended)
docker-compose up -d

# OR install locally
pip install -r requirements.txt
```

### Run Your First Test

```bash
# Comprehensive test (350 phrases) - Docker
docker-compose exec ash-thrash python src/comprehensive_testing.py

# Comprehensive test (350 phrases) - Local
python src/comprehensive_testing.py

# Quick validation (10 phrases) - Docker  
docker-compose exec ash-thrash python src/quick_validation.py

# Quick validation (10 phrases) - Local
python src/quick_validation.py
```

### Check Results

- **View Results:** `./results/comprehensive/` directory
- **API Access:** http://localhost:8884/api/test/status
- **Health Check:** http://localhost:8884/health

---

## üìä Dashboard Integration

### Integration with Ash-Dash

Ash-Thrash integrates seamlessly with [ash-dash](https://github.com/The-Alphabet-Cartel/ash-dash) to provide real-time testing metrics:

```bash
# Copy integration components to your ash-dash repository
cp dashboard/routes.js ../ash-dash/routes/testing.js
cp dashboard/styles/testing-dashboard.css ../ash-dash/public/css/
cp dashboard/templates/testing-section.html ../ash-dash/views/partials/
```

**Add to ash-dash server.js:**
```javascript
const testingRoutes = require('./routes/testing');
app.use('/api/testing', testingRoutes);
```

**Dashboard Features:**
- üìä **Real-time Test Results** - Latest pass rates and performance
- üéØ **Goal Achievement Tracking** - Visual progress toward targets
- üìà **Performance Trends** - Historical testing data over time
- üîç **Detailed Failure Analysis** - See exactly which phrases failed
- ‚ö° **One-Click Testing** - Trigger tests directly from dashboard

### Standalone Dashboard

Don't want to modify ash-dash? Ash-Thrash includes its own dashboard:

- **Testing Dashboard:** http://localhost:8884
- **API Documentation:** http://localhost:8884/api/docs
- **Real-time Status:** http://localhost:8884/api/test/status
- **Historical Data:** http://localhost:8884/api/test/history

### API Endpoints

```bash
# Get current testing status
curl http://localhost:8884/api/test/status

# Trigger comprehensive test
curl -X POST http://localhost:8884/api/test/run

# Get latest results
curl http://localhost:8884/api/test/results/latest

# Get performance trends (last 30 days)
curl http://localhost:8884/api/test/history?days=30

# Download detailed results
curl http://localhost:8884/api/test/results/download/comprehensive_test_results_1690380000.json
```

---

## üîß Configuration

### Environment Configuration (.env)

```bash
# Core NLP Server Settings
NLP_SERVER_HOST=10.20.30.16        # Your NLP server IP
NLP_SERVER_PORT=8881                # Your NLP server port
NLP_SERVER_URL=http://10.20.30.16:8881

# Performance Settings  
MAX_CONCURRENT_TESTS=5              # Parallel test execution
TEST_TIMEOUT_SECONDS=10             # Per-test timeout
RESULTS_RETENTION_DAYS=30           # How long to keep results

# API Configuration
API_PORT=8884                       # Testing API port
API_HOST=0.0.0.0                   # API host binding

# Scheduling (when running with Docker)
ENABLE_SCHEDULED_TESTING=true
COMPREHENSIVE_TEST_SCHEDULE="0 */6 * * *"    # Every 6 hours
QUICK_VALIDATION_SCHEDULE="0 * * * *"        # Every hour

# Optional Database
ENABLE_DATABASE=false               # Set to true for PostgreSQL storage
DATABASE_URL=postgresql://user:pass@localhost:5432/ash_testing
```

### Testing Goals (config/testing_goals.json)

Customize your testing targets:

```json
{
  "definite_high": {
    "target_pass_rate": 100.0,
    "description": "High Priority Crisis (Safety First!)",
    "critical": true,
    "alert_on_failure": true
  },
  "definite_none": {
    "target_pass_rate": 95.0,
    "description": "No Priority Crisis (Prevent False Positives)",  
    "critical": true,
    "alert_on_failure": true
  }
}
```

### Server Configuration (config/server_config.json)

Fine-tune connection settings:

```json
{
  "nlp_servers": {
    "primary": {
      "host": "10.20.30.16",
      "port": 8881,
      "timeout": 10,
      "retry_attempts": 3
    }
  },
  "performance": {
    "max_concurrent_tests": 5,
    "connection_pool_size": 10
  }
}
```

---

## üìà Features & Capabilities

### üß™ **Comprehensive Testing Engine**
- **350 Unique Test Phrases** - Carefully crafted for every crisis scenario
- **7 Priority Categories** - From high-crisis to non-crisis validation
- **Concurrent Execution** - 5 parallel requests for faster testing
- **Real-time Progress** - Live updates on test execution and failures
- **Detailed Metrics** - Speed, accuracy, confidence, and error analysis

### üìä **Advanced Performance Analysis**  
- **Goal Achievement Tracking** - Monitor progress against your specific targets
- **Category-Level Breakdown** - See performance for each priority level
- **Historical Trend Analysis** - Track improvements and regressions over time
- **Confidence Distribution** - Understand model certainty patterns
- **Response Time Monitoring** - Identify performance bottlenecks

### üîÑ **Automated Testing & Monitoring**
- **Scheduled Comprehensive Tests** - Run full 350-phrase suite every 6 hours
- **Quick Health Checks** - 10-phrase validation every hour  
- **Automated Result Storage** - JSON files ready for dashboard integration
- **Health Monitoring** - Service availability and performance checks
- **Cleanup & Maintenance** - Automatic old result removal

### üéõÔ∏è **Dashboard & Integration**
- **Seamless ash-dash Integration** - Drop-in components for existing dashboard
- **Standalone API Server** - Independent testing interface
- **Real-time Result Display** - Live updates in dashboard
- **Visual Goal Tracking** - Progress bars and achievement status
- **One-Click Manual Testing** - Trigger tests from web interface

### üê≥ **Production-Ready Deployment**
- **Docker-First Design** - Consistent environment across systems
- **Health Checks & Auto-restart** - Robust service management
- **Configurable Scheduling** - Customizable test frequency
- **Resource Management** - Controlled concurrent execution
- **Database Integration** - Optional PostgreSQL for historical data

### üîç **Safety & Reliability Focus**
- **Safety-First Testing** - 100% catch rate required for high-priority crises
- **False Positive Prevention** - 95% accuracy for non-crisis messages
- **Edge Case Coverage** - "Maybe" categories test borderline scenarios
- **Escalation Safety** - Allow priority increases but prevent dangerous decreases
- **Community Language Adapted** - Real-world phrases from LGBTQIA+ community

---

## üìã Usage Examples

### Basic Testing Commands

```bash
# Full comprehensive test (350 phrases)
python src/comprehensive_testing.py

# Quick health check (10 phrases)  
python src/quick_validation.py

# Test specific category only
python src/comprehensive_testing.py --category definite_high

# Generate performance report
python scripts/generate_report.py --days 7 --format html
```

### Docker Operations

```bash
# Start all services
docker-compose up -d

# Run comprehensive test in container
docker-compose exec ash-thrash python src/comprehensive_testing.py

# Run quick validation
docker-compose exec ash-thrash python src/quick_validation.py

# View real-time logs
docker-compose logs -f ash-thrash

# Restart services
docker-compose restart

# Stop all services
docker-compose down
```

### API Testing & Integration

```bash
# Check system health
curl http://localhost:8884/health

# Get current testing status
curl http://localhost:8884/api/test/status

# Trigger new comprehensive test
curl -X POST http://localhost:8884/api/test/run \
  -H "Content-Type: application/json" \
  -d '{"priority": "comprehensive"}'

# Get latest test results
curl http://localhost:8884/api/test/results/latest | jq '.'

# Get performance trends (last 30 days)
curl "http://localhost:8884/api/test/history?days=30" | jq '.trends'

# Download specific result file
curl -O http://localhost:8884/api/test/results/download/comprehensive_test_results_1690380000.json
```

### Advanced Configuration

```bash
# Run with custom NLP server
NLP_SERVER_URL=http://192.168.1.100:8881 python src/comprehensive_testing.py

# Run with increased concurrency
MAX_CONCURRENT_TESTS=10 python src/comprehensive_testing.py

# Run with custom timeout
TEST_TIMEOUT_SECONDS=15 python src/comprehensive_testing.py

# Generate detailed report with charts
python scripts/generate_report.py --days 30 --include-charts --output-dir ./reports/
```

---

## üìÅ Results & Data Management

### Result Storage Structure

```
results/
‚îú‚îÄ‚îÄ comprehensive/          # Full 350-phrase test results
‚îÇ   ‚îú‚îÄ‚îÄ comprehensive_test_results_1690380000.json
‚îÇ   ‚îú‚îÄ‚îÄ comprehensive_test_results_1690402800.json
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ quick_validation/       # Quick 10-phrase health checks
‚îÇ   ‚îú‚îÄ‚îÄ quick_validation_1690380600.json
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ reports/               # Generated performance reports
‚îÇ   ‚îú‚îÄ‚îÄ weekly_report_2025-07-26.html
‚îÇ   ‚îú‚îÄ‚îÄ monthly_trends_2025-07.json
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ backups/              # Automated result backups
    ‚îî‚îÄ‚îÄ backup_2025-07-26.tar.gz
```

### Result Format & Schema

**Comprehensive Test Results:**
```json
{
  "test_metadata": {
    "timestamp": "2025-07-26T10:30:00Z",
    "total_phrases_tested": 350,
    "test_type": "comprehensive_350_phrase_suite",
    "nlp_server_url": "http://10.20.30.16:8881",
    "total_execution_time_seconds": 87.3
  },
  "overall_results": {
    "total_passed": 298,
    "total_failed": 52,
    "total_errors": 0,
    "overall_pass_rate": 85.1,
    "avg_response_time_ms": 145.2,
    "avg_processing_time_ms": 89.7
  },
  "goal_achievement": {
    "summary": {
      "goals_achieved": 6,
      "total_goals": 7,
      "achievement_rate": 85.7,
      "overall_status": "‚ö†Ô∏è 6/7 GOALS MET"
    },
    "definite_high": {
      "target_rate": 100.0,
      "actual_rate": 98.0,
      "goal_met": false,
      "status": "‚ùå MISSED"
    }
  },
  "category_results": {
    "definite_high": {
      "passed": 49,
      "total": 50,
      "pass_rate": 98.0,
      "avg_confidence": 0.847,
      "failures": [
        {
          "message": "I can't handle this anymore",
          "expected": "high",
          "detected": "medium", 
          "confidence": 0.623
        }
      ]
    }
  }
}
```

### Data Retention & Cleanup

```bash
# Automatic cleanup (runs daily at 2 AM)
# Keeps last 30 days by default

# Manual cleanup
bash scripts/cleanup_old_results.sh 30    # Keep last 30 days
bash scripts/cleanup_old_results.sh 7     # Keep last 7 days

# Backup before cleanup
bash scripts/backup_results.sh

# Restore from backup
tar -xzf results/backups/backup_2025-07-26.tar.gz
```

### Exporting & Analysis

```bash
# Export results to CSV for analysis
python scripts/export_to_csv.py --days 30 --output analysis.csv

# Generate comprehensive report
python scripts/generate_report.py --days 30 --format html --include-charts

# Export for external tools
python scripts/export_for_external.py --format elasticsearch
python scripts/export_for_external.py --format prometheus
```

---

## üîó Integration with Ash Ecosystem

### Connecting to Your Ash Setup

Ash-Thrash works with your existing Ash deployment without any modifications:

```bash
# Default connection (works with standard Ash setup)
NLP_SERVER_URL=http://10.20.30.16:8881

# Custom NLP server location
NLP_SERVER_URL=http://192.168.1.100:8881

# Testing different environments
NLP_SERVER_URL=http://ash-nlp-dev:8881     # Development
NLP_SERVER_URL=http://ash-nlp-prod:8881    # Production
```

### Ash-Dash Integration

**Option 1: Full Integration (Recommended)**
```bash
# Copy components to your ash-dash repository
cp dashboard/routes.js ../ash-dash/routes/testing.js
cp dashboard/styles/testing-dashboard.css ../ash-dash/public/css/
cp dashboard/templates/testing-section.html ../ash-dash/views/partials/

# Add to ash-dash server.js
echo 'const testingRoutes = require("./routes/testing");' >> ../ash-dash/server.js
echo 'app.use("/api/testing", testingRoutes);' >> ../ash-dash/server.js
```

**Option 2: API Integration Only**
```javascript
// Add to your ash-dash JavaScript
const testingApiUrl = 'http://localhost:8884';

// Fetch testing status
fetch(`${testingApiUrl}/api/test/status`)
  .then(response => response.json())
  .then(data => updateTestingDisplay(data));
```

### Multi-Environment Testing

```bash
# Test multiple NLP servers
docker-compose up -d
docker-compose exec ash-thrash python src/comprehensive_testing.py --server dev
docker-compose exec ash-thrash python src/comprehensive_testing.py --server staging  
docker-compose exec ash-thrash python src/comprehensive_testing.py --server prod

# Compare performance across environments
python scripts/compare_environments.py --environments dev,staging,prod
```

### CI/CD Integration

**GitHub Actions Example:**
```yaml
name: Ash Crisis Detection Testing
on:
  schedule:
    - cron: '0 */6 * * *'  # Every 6 hours
  workflow_dispatch:      # Manual trigger

jobs:
  crisis-detection-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          repository: The-Alphabet-Cartel/ash-thrash
      
      - name: Run comprehensive test
        run: |
          docker-compose up -d
          docker-compose exec ash-thrash python src/comprehensive_testing.py
          
      - name: Upload results
        uses: actions/upload-artifact@v3
        with:
          name: test-results
          path: results/comprehensive/
```

### Data Export for External Tools

```bash
# Export to Grafana/Prometheus
python scripts/export_metrics.py --format prometheus --output metrics.txt

# Export to ELK Stack
python scripts/export_logs.py --format elasticsearch --days 30

# Export to Datadog
python scripts/export_metrics.py --format datadog --api-key $DD_API_KEY

# Export to Google Sheets/Excel
python scripts/export_to_spreadsheet.py --format xlsx --output testing_results.xlsx
```

---

## üõ†Ô∏è Development & Customization

### Project Structure

```
ash-thrash/
‚îú‚îÄ‚îÄ src/                           # Core source code
‚îÇ   ‚îú‚îÄ‚îÄ comprehensive_testing.py   # Main 350-phrase test suite
‚îÇ   ‚îú‚îÄ‚îÄ quick_validation.py       # Quick health checks
‚îÇ   ‚îú‚îÄ‚îÄ test_data/                # Test phrase collections
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ high_priority.py      # High priority phrases
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ medium_priority.py    # Medium priority phrases
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ low_priority.py       # Low priority phrases  
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ none_priority.py      # Non-crisis phrases
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ maybe_high_medium.py  # Edge case phrases
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ maybe_medium_low.py   # Borderline phrases
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ maybe_low_none.py     # Minimal concern phrases
‚îÇ   ‚îú‚îÄ‚îÄ utils/                    # Utility modules
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api_client.py         # NLP server communication
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ results_processor.py  # Results analysis
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ report_generator.py   # Report generation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dashboard_integration.py # Dashboard helpers
‚îÇ   ‚îî‚îÄ‚îÄ api/                      # Testing API server
‚îÇ       ‚îú‚îÄ‚îÄ server.py             # Flask API server
‚îÇ       ‚îî‚îÄ‚îÄ routes/               # API endpoints
‚îú‚îÄ‚îÄ config/                       # Configuration files
‚îú‚îÄ‚îÄ dashboard/                    # Dashboard integration
‚îú‚îÄ‚îÄ docker/                       # Docker configurations
‚îú‚îÄ‚îÄ scripts/                      # Utility scripts
‚îî‚îÄ‚îÄ docs/                         # Documentation
```

### Adding New Test Categories

1. **Create Test Data Module:**
```python
# src/test_data/new_category.py
def get_new_category_phrases():
    return [
        {
            "message": "Your test phrase here",
            "expected_priority": "medium",
            "description": "Description of what this tests",
            "subcategory": "specific_scenario"
        },
        # ... more phrases
    ]
```

2. **Update Main Testing Script:**
```python
# src/comprehensive_testing.py
from test_data.new_category import get_new_category_phrases

# Add to _load_test_phrases method
new_category_phrases = get_new_category_phrases()
for phrase_data in new_category_phrases:
    phrases.append(TestPhrase(
        message=phrase_data["message"],
        expected_priority=phrase_data["expected_priority"],
        category="new_category",
        # ... other parameters
    ))
```

3. **Update Configuration:**
```json
// config/testing_goals.json
{
  "new_category": {
    "target_pass_rate": 75.0,
    "description": "New Category Description",
    "critical": false,
    "allow_escalation": false
  }
}
```

### Customizing Testing Logic

**Custom Evaluation Logic:**
```python
# src/utils/custom_evaluator.py
def custom_evaluation_logic(phrase, detected_priority):
    """Custom logic for evaluating test results"""
    
    # Example: Allow certain phrases to have flexible evaluation
    if phrase.category == "flexible_category":
        return flexible_evaluation(phrase, detected_priority)
    
    # Default evaluation
    return standard_evaluation(phrase, detected_priority)
```

**Custom Reporting:**
```python
# src/utils/custom_reporter.py
def generate_custom_report(results):
    """Generate custom format reports"""
    
    # Example: Generate Slack-formatted report
    slack_report = format_for_slack(results)
    
    # Example: Generate email-formatted report  
    email_report = format_for_email(results)
    
    return {
        'slack': slack_report,
        'email': email_report
    }
```

### Contributing Guidelines

1. **Fork the Repository**
```bash
git fork https://github.com/The-Alphabet-Cartel/ash-thrash.git
git clone https://github.com/YourUsername/ash-thrash.git
cd ash-thrash
git remote add upstream https://github.com/The-Alphabet-Cartel/ash-thrash.git
```

2. **Create Feature Branch**
```bash
git checkout -b feature/your-feature-name
```

3. **Development Setup**
```bash
# Install development dependencies
pip install -r requirements.txt
pip install -r requirements-dev.txt

# Install pre-commit hooks
pre-commit install

# Run tests
pytest tests/

# Run linting
black src/
flake8 src/
```

4. **Testing Your Changes**
```bash
# Test your changes don't break existing functionality
python src/comprehensive_testing.py --quick-test

# Test specific components
pytest tests/test_your_feature.py

# Integration test
docker-compose up -d
docker-compose exec ash-thrash python src/comprehensive_testing.py
```

5. **Submit Pull Request**
```bash
git add .
git commit -m "feat: add your feature description"
git push origin feature/your-feature-name
# Create PR on GitHub
```

### Advanced Configuration

**Custom NLP Server Integration:**
```python
# src/utils/custom_nlp_client.py
class CustomNLPClient:
    def __init__(self, base_url, custom_headers=None):
        self.base_url = base_url
        self.headers = custom_headers or {}
    
    def analyze_message(self, message, user_id, channel_id):
        # Custom integration logic
        return custom_analysis_result
```

**Performance Optimization:**
```python
# config/performance_config.json
{
  "concurrent_tests": 10,
  "batch_size": 50,
  "connection_pooling": true,
  "caching": {
    "enabled": true,
    "ttl_seconds": 300
  },
  "retry_policy": {
    "max_retries": 3,
    "backoff_factor": 2
  }
}
```

---

## üìö Documentation & Resources

### Complete Documentation

- **[üìñ Setup Guide](docs/setup.md)** - Detailed installation and configuration
- **[üöÄ Usage Guide](docs/usage.md)** - Complete command reference and examples  
- **[üîå API Documentation](docs/api.md)** - REST API endpoint reference
- **[üîß Integration Guide](docs/integration.md)** - Dashboard and CI/CD integration
- **[üêõ Troubleshooting](docs/troubleshooting.md)** - Common issues and solutions
- **[‚öôÔ∏è Configuration Reference](docs/configuration.md)** - All settings explained
- **[üìä Performance Tuning](docs/performance.md)** - Optimization guidelines

### Quick Reference

**Essential Commands:**
```bash
# Setup and start
bash setup.sh && docker-compose up -d

# Run comprehensive test  
docker-compose exec ash-thrash python src/comprehensive_testing.py

# Check status
curl http://localhost:8884/api/test/status

# View results
ls -la results/comprehensive/
```

**Key Configuration Files:**
- `.env` - Environment variables and server settings
- `config/testing_goals.json` - Testing targets and thresholds
- `config/server_config.json` - NLP server connection settings
- `docker-compose.yml` - Service orchestration

**Important Directories:**
- `src/test_data/` - Test phrase collections (350 phrases total)
- `results/comprehensive/` - Full test results storage
- `dashboard/` - ash-dash integration components
- `scripts/` - Utility and maintenance scripts

### Architecture Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     ‚îÇ    ‚îÇ                     ‚îÇ    ‚îÇ                     ‚îÇ
‚îÇ   Ash-Thrash        ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Ash NLP Server    ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ   Ash Discord Bot   ‚îÇ
‚îÇ   Testing Suite     ‚îÇ    ‚îÇ   (10.20.30.16)    ‚îÇ    ‚îÇ   (Crisis Detection)‚îÇ
‚îÇ                     ‚îÇ    ‚îÇ                     ‚îÇ    ‚îÇ                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ                                                        ‚îÇ
           ‚îÇ                                                        ‚îÇ
           ‚ñº                                                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     ‚îÇ                              ‚îÇ                     ‚îÇ
‚îÇ   Ash-Dash          ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ   Discord Server    ‚îÇ
‚îÇ   Analytics         ‚îÇ      Real Crisis Detection   ‚îÇ   (Live Community)  ‚îÇ
‚îÇ   Dashboard         ‚îÇ                              ‚îÇ                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Data Flow:**
1. **Ash-Thrash** sends test phrases to **Ash NLP Server**
2. **NLP Server** analyzes phrases and returns crisis levels
3. **Ash-Thrash** compares results against expected outcomes
4. **Results** are stored and made available to **Ash-Dash**
5. **Dashboard** displays real-time testing metrics and trends

### Community & Support

**Getting Help:**
- üêõ **GitHub Issues** - Bug reports and feature requests
- üí¨ **Discord Community** - Real-time help and discussions: https://discord.gg/alphabetcartel
- üìß **Email Support** - Direct contact for urgent issues
- üìñ **Documentation** - Comprehensive guides and references

**Community Resources:**
- üé• **Video Tutorials** - Setup and usage walkthroughs  
- üìù **Blog Posts** - Best practices and case studies
- üõ†Ô∏è **Community Tools** - User-contributed utilities and extensions
- üìä **Performance Benchmarks** - Community testing results

**Contributing:**
- ü§ù **Code Contributions** - Features, bug fixes, improvements
- üìö **Documentation** - Help improve guides and references
- üß™ **Test Phrase Contributions** - Add more community-specific phrases
- üé® **Dashboard Components** - UI/UX improvements
- üêõ **Bug Reports** - Help identify and fix issues

---

## ü§ù Support & Community

### Getting Help & Support

**Primary Support Channels:**
- üêõ **[GitHub Issues](https://github.com/The-Alphabet-Cartel/ash-thrash/issues)** - Bug reports, feature requests, and technical questions
- üí¨ **[The Alphabet Cartel Discord](https://discord.gg/alphabetcartel)** - Community support, real-time help, and development discussions
- üìñ **[Documentation Wiki](https://github.com/The-Alphabet-Cartel/ash-thrash/wiki)** - Comprehensive guides, tutorials, and FAQs
- üìß **Direct Contact** - For urgent issues or private concerns

**Community Resources:**
- üé• **Video Tutorials** - Setup walkthroughs and usage demonstrations
- üìù **Best Practices Guide** - Community-tested optimization strategies  
- üõ†Ô∏è **Community Tools** - User-contributed utilities and extensions
- üìä **Benchmark Results** - Performance comparisons and testing outcomes

### Contributing to Ash-Thrash

We welcome contributions from the community! Here's how you can help:

**üîß Code Contributions:**
- Bug fixes and performance improvements
- New testing categories and edge cases
- Dashboard enhancements and visualizations
- API improvements and new endpoints
- Docker optimization and deployment tools

**üìù Documentation Contributions:**
- Improve setup and usage guides
- Add troubleshooting scenarios
- Create video tutorials and walkthroughs
- Translate documentation for international users
- Write best practices and optimization guides

**üß™ Testing & Validation:**
- Add community-specific test phrases
- Test on different environments and configurations
- Report edge cases and unusual scenarios
- Validate integration with different Ash setups
- Performance testing and benchmarking

**üé® Design & UX:**
- Dashboard component improvements
- Visual design enhancements
- User experience optimization
- Accessibility improvements
- Mobile-responsive design

### Development Guidelines

**Getting Started:**
```bash
# Fork and clone
git clone https://github.com/YourUsername/ash-thrash.git
cd ash-thrash

# Set up development environment
bash setup.sh
pip install -r requirements-dev.txt
pre-commit install

# Make your changes
git checkout -b feature/your-amazing-feature

# Test your changes
pytest tests/
docker-compose up -d && docker-compose exec ash-thrash python src/comprehensive_testing.py

# Submit for review
git push origin feature/your-amazing-feature
# Create pull request on GitHub
```

**Code Standards:**
- Follow PEP 8 style guidelines
- Include comprehensive tests for new features
- Update documentation for any API changes
- Ensure Docker compatibility
- Add logging for debugging purposes

---

## üìÑ License & Legal

This project is part of **The Alphabet Cartel's** Ash ecosystem and is available under the MIT License. See the [LICENSE](LICENSE) file for complete details.

**Third-Party Acknowledgments:**
- Flask and related libraries for API framework
- Docker for containerization platform
- PostgreSQL for optional data storage
- Chart.js for dashboard visualizations

---

## üôè Acknowledgments & Credits

### Core Development Team
- **The Alphabet Cartel Development Team** - Primary development and maintenance
- **Community Contributors** - Features, bug fixes, and improvements
- **Testing Team** - Quality assurance and validation

### Community Support
- **The Alphabet Cartel Crisis Response Team** - Real-world testing feedback and validation
- **LGBTQIA+ Community Members** - Language pattern identification and cultural context guidance  
- **Mental Health Professionals** - Clinical guidance on crisis detection best practices
- **Beta Testing Community** - Early adoption feedback and system refinement

### Technical Acknowledgments
- **Ash Bot Community** - Integration testing and ecosystem validation
- **Discord.py Community** - Bot framework guidance and best practices
- **Docker Community** - Containerization patterns and deployment strategies
- **Open Source Contributors** - Libraries, tools, and frameworks that make this possible

### Research & Validation Partners
- **AI/ML Research Community** - Foundational work in depression detection and NLP
- **Crisis Intervention Specialists** - Evidence-based practices for mental health crisis response
- **Mental Health Informatics** - Research into AI applications for crisis detection
- **LGBTQIA+ Advocacy Groups** - Community-specific language and cultural sensitivity guidance

---

## üöÄ What's Next?

### Planned Features

**üìà Enhanced Analytics (v2.0)**
- Machine learning-powered trend analysis
- Predictive failure detection
- Advanced performance correlation analysis
- Custom alerting and notification systems

**üîß Integration Expansions (v2.1)**
- Slack integration for team notifications
- Webhook support for external systems
- GitHub Actions templates for CI/CD
- Prometheus/Grafana metrics export

**üß™ Advanced Testing (v2.2)**
- A/B testing capabilities for model comparisons
- Load testing for performance validation
- Chaos testing for reliability verification
- Multi-language testing support

**üéõÔ∏è Enhanced Dashboard (v2.3)**
- Real-time WebSocket updates
- Interactive performance tuning
- Custom test scenario builder
- Advanced visualization options

### Roadmap

- **Q3 2025:** Enhanced analytics and machine learning insights
- **Q4 2025:** Advanced integration ecosystem and webhook support
- **Q1 2026:** Multi-language and international community support
- **Q2 2026:** Advanced AI-powered testing and optimization features

---

**Built with üñ§ for comprehensive crisis detection testing.**

*"Thrashing the system so it never fails when it matters most."*

---

**üîó Ecosystem Links:**
- **Main Bot:** [github.com/The-Alphabet-Cartel/ash](https://github.com/The-Alphabet-Cartel/ash)
- **NLP Server:** [github.com/The-Alphabet-Cartel/ash-nlp](https://github.com/The-Alphabet-Cartel/ash-nlp)  
- **Dashboard:** [github.com/The-Alphabet-Cartel/ash-dash](https://github.com/The-Alphabet-Cartel/ash-dash)
- **Testing Suite:** [github.com/The-Alphabet-Cartel/ash-thrash](https://github.com/The-Alphabet-Cartel/ash-thrash) *(You are here)*
- **Community:** [discord.gg/alphabetcartel](https://discord.gg/alphabetcartel)